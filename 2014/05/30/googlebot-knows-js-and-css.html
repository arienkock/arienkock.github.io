<!doctype html>
<html class="no-js" lang="">
  <head>
    <meta charset="utf-8">
    <meta name="description" content="Arien Kock is Positor, a freelance Java web developer and consultant. I build connected applications and continuous delivery pipelines. This is home to my blog and professional profile.">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Googlebot Knows JS and CSS - Positor</title>
	<link rel="icon" href="/images/favicon.png" type="image/png">
	<link rel="apple-touch-icon" href="/images/favicon.png">
	<link rel="shortcut icon" href="/images/favicon.png" type="image/png">

    <link rel="apple-touch-icon" href="apple-touch-icon.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="/styles/main.css">
	
	<link rel="stylesheet" href="/styles/highlight/solarized-dark-custom.css">
  </head>
  <body>
    <!--[if lt IE 10]>
      <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
    
    <div class="container">
		<div class="header">
			<div class="logo">
				<a href="/">
				<h1>Positor</h1>
				<p>Building solutions with code</p>
				</a>
			</div>
			<!--div class="menu">
				<div class="item"></div>
				<div class="item"></div>
				<div class="item navItem"><a href="/">Blog</a></div>
				<div class="item navItem"><a href="/profile.html">Profile</a></div>
			</div-->
		</div>
		<div class="content">
			
<div class="article">
<h1 class="articleTitle">Googlebot Knows JS and CSS</h1>
<div class="posted-on-date">Posted on 2014-5-30</div>
<p>A week ago Google came out with <a href="http://googlewebmastercentral.blogspot.co.uk/2014/05/understanding-web-pages-better.html">big news</a>. Now all your single page apps get indexed properly without a static page fallback. Pages that rely on <code>pushState</code> for navigation used to have to do extra work to <a href="https://developers.google.com/webmasters/ajax-crawling/docs/learn-more">make their sites indexable</a>.</p>
<h3 id="the-good">The good</h3>
<p>Google being the gods of search and by extension the masters to which all of e-commerce caters, is now saying that they can better handle your complex webapps. You can use Ajax calls from the get-go and not pay a hefty price. This makes development simpler and that is good. </p>
<p>No longer can you hide away content and pretend like it&#39;s part of your page as part of some SEO scheme. With CSS being rendered, the visual position and thus the relevance of content can be more accurately judged by Google&#39;s indexing mechanism. This means better search results and this is even better.</p>
<h3 id="the-bad">The bad</h3>
<p>I think the best developers are lazy developers. By that I mean that a lazy developer will do a repetitive task only a few times before automating it. The essence of good code is reusability. However, there is also a bad kind of lazy. The lazy developer that is <strong>TOO</strong> lazy to automate will forego the chance to make a generic solution in favor of a less sophisticated solution. The promise being that he won&#39;t have to do that exact task again <strong>him-/herself</strong> or that the burden of maintenance will fall on the shoulders of someone else or, best of all, no one at all. If you <strong>can</strong> hack together a page with asynchronous calls with existing services doesn&#39;t mean you <strong>should</strong>. The goal of maintainability and performance suffers in the face of ad-hoc solutions. This is bad.</p>
<p>As mobile devices get more powerful they can bear a heavier processing load than before. You can create more complex interfaces that improve the UX aspect of a webapp. That&#39;s great as long as that&#39;s the actual reason. Why would a page <strong>NOT</strong> load the main content in the first request? Now you can argue that if it&#39;s fast enough, it doesn&#39;t matter, because Google said so. They didn&#39;t, actually, if you read that article, they suggest you degrade gracefully. Google and humans are not the only consumers on the web. There are other bots, applications and not all of them can fetch using a headless browser like <a href="http://phantomjs.org/">PhantomJs</a>. Google can&#39;t process pages as fast with client side rendering as they could before and most other parties definitely can&#39;t.</p>
<h3 id="don-t-change-too-much">Don&#39;t change too much</h3>
<p>I like the idea of not needing to create a static version of a page for SEO purposes only. Heck, I think it&#39;s just swell. However, if the future of the internet consists of pages that need 5+ requests before it&#39;s usable, then someone has failed somewhere along the line.</p>

</div>

		</div>
	</div>
    
    <script>
      (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
      function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
      e=o.createElement(i);r=o.getElementsByTagName(i)[0];
      e.src='https://www.google-analytics.com/analytics.js';
      r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
      ga('create','UA-19252179-3');ga('send','pageview');
    </script>
	<script src="/scripts/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>
